# Auto-Scaling Feature Documentation

## Overview

The load balancer now includes **intelligent auto-scaling** that automatically adjusts the number of backend servers based on incoming request load.

## How It Works

The auto-scaler monitors request rates every 10 seconds (configurable) and makes scaling decisions:

### Scale UP â¬†ï¸

-   **When**: Request rate exceeds threshold (default: 50 req/s)
-   **Action**: Adds 1-3 servers automatically
-   **Limit**: Won't exceed maximum server count (default: 20)

### Scale DOWN â¬‡ï¸

-   **When**: Request rate falls below threshold (default: 10 req/s)
-   **Action**: Removes 1-2 servers automatically
-   **Limit**: Won't go below minimum server count (default: 1)

## Configuration

Edit `config.properties` to customize auto-scaling behavior:

```properties
# Auto-scaling configuration
autoscaling.enabled=true                    # Enable/disable auto-scaling
autoscaling.min.servers=1                   # Minimum servers to maintain
autoscaling.max.servers=20                  # Maximum servers allowed
autoscaling.check.interval=10               # Check interval in seconds
autoscaling.scale.up.threshold=50           # Scale up when req/s > this
autoscaling.scale.down.threshold=10         # Scale down when req/s < this
```

## Example Scenarios

### Scenario 1: Traffic Spike

```
Initial: 3 servers, 20 req/s
â†“
Traffic increases to 100 req/s
â†“
Auto-scaler detects: "100 req/s > 50 req/s threshold"
â†“
Action: Adds 2 servers (3 â†’ 5)
â†“
Result: Load distributed across 5 servers (20 req/s each)
```

### Scenario 2: Traffic Drop

```
Current: 5 servers, 60 req/s
â†“
Traffic decreases to 8 req/s
â†“
Auto-scaler detects: "8 req/s < 10 req/s threshold"
â†“
Action: Removes 2 servers (5 â†’ 3)
â†“
Result: 3 servers handling 8 req/s efficiently
```

## Monitoring

Watch the logs to see auto-scaling in action:

```
ðŸ“Š Load Monitor: 55.2 req/s (552 requests in 10s) | 3 servers | 18 req/s per server
ðŸ“ˆ AUTO-SCALE UP: High load detected! Adding 2 server(s)...
INFO: âœ“ Server server-8084 started on port 8084
INFO: âœ“ Added node server-8084 to the ring with 150 virtual nodes. Total nodes: 4
INFO: âœ“ Server server-8085 started on port 8085
INFO: âœ“ Added node server-8085 to the ring with 150 virtual nodes. Total nodes: 5
INFO: âœ“ Scaled up to 5 servers
```

## Testing Auto-Scaling

### 1. Start with default config (3 servers)

```bash
./run.sh
```

### 2. Generate high load to trigger scale-up

```bash
# Send 1000 requests quickly
./load-test.sh
```

You'll see logs like:

```
ðŸ“Š Load Monitor: 95.3 req/s (953 requests in 10s) | 3 servers | 31 req/s per server
ðŸ“ˆ AUTO-SCALE UP: High load detected! Adding 2 server(s)...
âœ“ Scaled up to 5 servers
```

### 3. Wait for load to drop (scale-down)

After load test completes and traffic drops:

```
ðŸ“Š Load Monitor: 2.1 req/s (21 requests in 10s) | 5 servers | 0 req/s per server
ðŸ“‰ AUTO-SCALE DOWN: Low load detected. Removing 2 server(s)...
âœ“ Scaled down to 3 servers
```

## Manual Scaling (Override Auto-Scaling)

You can still manually scale even with auto-scaling enabled:

```bash
# Scale to exactly 10 servers
curl "http://localhost:8080/scale?target=10"

# Add 3 more servers
curl "http://localhost:8080/scale-up?count=3"

# Remove 2 servers
curl "http://localhost:8080/scale-down?count=2"
```

## Best Practices

1. **Set realistic thresholds**:

    - Too low scale-up threshold â†’ wasteful over-provisioning
    - Too high scale-down threshold â†’ servers stay idle

2. **Monitor costs**:

    - Each server consumes resources
    - Set appropriate max_servers limit

3. **Consider latency**:

    - New servers take ~2 seconds to start
    - Factor this into your scaling strategy

4. **Test with real traffic patterns**:
    - Test during peak hours
    - Test gradual vs sudden spikes

## Disabling Auto-Scaling

To disable and use manual scaling only:

```properties
autoscaling.enabled=false
```

Then restart the load balancer.

## Advantages

âœ… **Elastic**: Automatically handles traffic variations
âœ… **Cost-effective**: Scales down during low traffic
âœ… **Resilient**: Adds capacity before overload
âœ… **Hands-off**: No manual intervention needed

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Load Balancer Process          â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Auto-Scale Scheduler        â”‚  â”‚
â”‚  â”‚  (runs every 10s)            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚             â”‚                       â”‚
â”‚             â”œâ”€ Monitor request rate â”‚
â”‚             â”œâ”€ Calculate: req/s     â”‚
â”‚             â”œâ”€ Compare to thresholdsâ”‚
â”‚             â””â”€ Scale up/down        â”‚
â”‚                                     â”‚
â”‚  Consistent Hash Ring               â”‚
â”‚  â”Œâ”€â” â”Œâ”€â” â”Œâ”€â” â”Œâ”€â” ... â”Œâ”€â”          â”‚
â”‚  â””â”€â”˜ â””â”€â”˜ â””â”€â”˜ â””â”€â”˜     â””â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€
           â–¼      â–¼      â–¼      â–¼
        Server Server Server Server
        (dynamically added/removed)
```

## Metrics Logged

Every check interval, you'll see:

-   **Request rate**: req/s
-   **Total requests**: in the interval
-   **Server count**: current number
-   **Req/s per server**: distribution

Example:

```
ðŸ“Š Load Monitor: 42.5 req/s (425 requests in 10s) | 4 servers | 10 req/s per server
```

---

**Pro Tip**: Start with conservative thresholds and adjust based on observed behavior!
